---
layout: post
title: "Computer Vision Semester Review - Part.3"
date: "2019-05-04 21:06:23 -0400"
categories: [CV]
mathjax: true
---

This is a personal notes about Computer Vision class, CS5670, in Cornell Tech.

Covering chapters: **Two-View Geometry**, **Light**, **Photometric Stereo**

<!--more-->

# Two-View Geometry

![image](https://user-images.githubusercontent.com/13166286/57186688-c5e69300-6eb1-11e9-9cdf-3306ca2d0d1f.png){:.w80.ctr-img}

## Fundamental Matrix

| $\mathbf{F}$ usage | maps **points** in image 1 to **lines** in image 2 |
| Epipolar Line in image 2 | $\mathbf{Fp}$ |
| Epipolar Line in image 1 | $\mathbf{F^Tq}$ |
| Epipolar Constraint on $p$, $q$ | $\mathbf{q^TFp}=0$ |
| **The epipoles** $\mathbf{e}_1$, $\mathbf{e}_2$ | All of epipolar lines in image pass thru the epipole |
| Epipoles and $\mathbf{F}$ | $\mathbf{Fe_1} = 0$ and $\mathbf{Fe_2} = 0$ | 
| Rank of F | $rank(\mathbf{F}) = 2$ |

## Deriving Fundamental Matrix

![image](https://user-images.githubusercontent.com/13166286/57187026-114f7000-6eb7-11e9-9594-e9d781d760d5.png){:.w50.ctr-img}

Where:

| $K_1$: intrinsics of camera 1 | $K_2$: intrinsics of camera 2 | $R$: rotation of image 2 w.r.t. camera 1 |
| $\large{\tilde{p} = \mathbf{K_1^{-1}p}}$ | $\large{\tilde{q} = \mathbf{K_2^{-1}q}}$ | Epipolar plane: $\mathbf{t} \times \mathbf{\tilde{p}}$ |

Therefore, the epipolar plane **contains** the ray thru $q$:

$$ \large{(R^T\tilde{q})^T ( \mathbf{t} \times \mathbf{\tilde{p}} )} = 0  $$

$$ \large{\tilde{q}R ( \mathbf{t} \times \mathbf{\tilde{p}} )} = 0  $$

Also we can write cross product with $\mathbf{t}$ as $[\mathbf{t}]_{\times}$:

$$ \large{\mathbf{t} \times \mathbf{\tilde{p}} = [\mathbf{t}]_{\times} \mathbf{\tilde{p}}} $$

So...

![image](https://user-images.githubusercontent.com/13166286/57187161-32b15b80-6eb9-11e9-9397-0d9f0aff402c.png){:.w50.ctr-img}

---

# Light

## Lambertian Reflectance

![image](https://user-images.githubusercontent.com/13166286/57188152-cd189b80-6ec7-11e9-8fd9-3487eebc6f7f.png){:.w50.ctr-img}

1. Reflected energy is proportional to cosine of angle
between L and N 
2.. Measured intensity is viewpoint-independent

## Image Formation Model

$$ \large{\mathbf{I = k_d N L}} $$

Where:

| $\mathbf{I}$: observed image intensity | $\mathbf{k_d}$: object albedo |
| $\mathbf{N}$: surface normal | $\mathbf{L}$: light source direction |

---

# Photometric Stereo

## Photometric Stereo - Get Normal

![image](https://user-images.githubusercontent.com/13166286/57188209-d1918400-6ec8-11e9-8fee-9edf85eeb7a6.png){:.w80.ctr-img}

So for each **pixel** of the image, we have the equations:

![image](https://user-images.githubusercontent.com/13166286/57188218-f259d980-6ec8-11e9-8924-5cd7da3b838a.png){:.w300px.ctr-img}

$$ \large{\mathbf{G = L^{-1}I}} $$

$$ \large{\mathbf{k_d = ||G||}} $$

$$ \large{\mathbf{N = \frac{1}{k_d}G}} $$

So we can get the surface normal for each pixel.  We can also add more lights to do least square solution.

## Photometric Stereo - Get Depth

We can think of depths like **integration of normals**.

We can solve a linear system to get depths that **best agrees** with the given surface normals.

This approach ignores the effects of: 
* Specular Reflection
* Refraction
* Interreflections
* Subsurface Scattering
